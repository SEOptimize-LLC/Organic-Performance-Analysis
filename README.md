# Organic Performance Analyzer

Advanced SEO analysis tool that conducts in-depth organic performance analysis combining Google Search Console (GSC) data with DataForSEO insights, powered by AI-generated actionable recommendations.

## ğŸ¯ Overview

This tool is designed to surface concrete growth opportunities and prioritize actions for maximum ROI, not to generate vanity reports or simple status summaries. It provides:

- **Quick-win opportunities** with high-impact, low-effort optimizations
- **Content decay detection** with recovery recommendations
- **Competitor analysis** with keyword gap identification
- **Brand vs non-brand segmentation** with growth headroom analysis
- **AI-powered insights** using cutting-edge LLMs via OpenRouter

## âœ¨ Features

### Data Collection
- Multi-window GSC data collection (28d, 90d, 180d, 365d)
- Year-over-year comparison analysis
- Device and country segmentation
- Query and page-level metrics

### DataForSEO Integration
- Ranked keywords retrieval
- Auto-discovery of competitors
- Keyword suggestions and gaps
- SERP feature analysis

### Analysis Engine
- Opportunity scoring model with 5 components:
  - Search volume score
  - Position potential score
  - CTR gap score
  - Commercial value score
  - Trend direction score
- Content decay classification
- Brand dependency analysis

### AI-Powered Insights
Multiple LLM models available via OpenRouter:
- `openai/gpt-4.1-mini`
- `openai/gpt-5-mini`
- `anthropic/claude-haiku-4.5`
- `anthropic/claude-sonnet-4.5`
- `google/gemini-3-pro-preview`
- `google/gemini-2.5-flash-preview-09-2025`
- `x-ai/grok-4-fast`
- `deepseek/deepseek-r1-0528-qwen3-8b`

### Export Options
- **Excel reports** with multiple worksheets
- **PDF reports** with formatted sections
- **CSV exports** for individual data tables

## ğŸš€ Deployment

### Streamlit Cloud

1. Fork or clone this repository
2. Connect to Streamlit Cloud
3. Add secrets in the Streamlit Cloud dashboard

### Local Development

```bash
# Clone the repository
cd "Organic Performance Analyzer"

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
```

## âš™ï¸ Configuration

### Streamlit Secrets

Create a `.streamlit/secrets.toml` file with your API credentials:

```toml
[gsc]
client_id = "your-google-client-id"
client_secret = "your-google-client-secret"
redirect_uri = "http://localhost:8501"

[dataforseo]
login = "your-dataforseo-login"
password = "your-dataforseo-password"

[openrouter]
api_key = "your-openrouter-api-key"
```

### Google Cloud Console Setup

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select existing
3. Enable the Search Console API
4. Create OAuth 2.0 credentials (Web application)
5. Add authorized redirect URIs
6. Download credentials and add to secrets

### DataForSEO Setup

1. Sign up at [DataForSEO](https://dataforseo.com/)
2. Get your API login and password from the dashboard
3. Add to Streamlit secrets

### OpenRouter Setup

1. Sign up at [OpenRouter](https://openrouter.ai/)
2. Create an API key
3. Add to Streamlit secrets

## ğŸ“Š Usage

1. **Connect to GSC**: Click the authorization button and complete OAuth flow
2. **Select Property**: Choose from available GSC properties
3. **Configure Analysis**:
   - Select analysis period (28d to 365d)
   - Set minimum impressions filter
   - Enable/disable YoY comparison
   - Add brand terms for segmentation
   - Choose AI model for insights
4. **Run Analysis**: Click the "Run Analysis" button
5. **Review Results**: Navigate through the analysis tabs
6. **Export Reports**: Download Excel or PDF reports

## ğŸ“ Project Structure

```
Organic Performance Analyzer/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py             # Application settings
â”‚   â””â”€â”€ api_config.py           # API configuration
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth_service.py         # GSC OAuth handling
â”‚   â”œâ”€â”€ cache_service.py        # Data caching
â”‚   â””â”€â”€ rate_limiter.py         # API rate limiting
â”œâ”€â”€ collectors/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ gsc_collector.py        # GSC data collection
â”‚   â””â”€â”€ dataforseo_client.py    # DataForSEO API client
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_normalizer.py      # Data normalization
â”‚   â”œâ”€â”€ opportunity_scorer.py   # Opportunity scoring
â”‚   â”œâ”€â”€ decay_detector.py       # Content decay detection
â”‚   â””â”€â”€ brand_classifier.py     # Brand classification
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analysis_agent.py       # AI analysis agent
â”‚   â””â”€â”€ prompts.py              # Analysis prompts
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ charts.py               # Plotly charts
â”‚   â”œâ”€â”€ metrics.py              # Metric cards
â”‚   â””â”€â”€ tables.py               # Data tables
â”œâ”€â”€ exporters/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ excel_exporter.py       # Excel export
â”‚   â”œâ”€â”€ pdf_exporter.py         # PDF export
â”‚   â””â”€â”€ report_generator.py     # Report orchestration
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ logger.py               # Logging utilities
    â”œâ”€â”€ helpers.py              # Helper functions
    â””â”€â”€ validators.py           # Input validation
```

## ğŸ”§ Analysis Methodology

### Opportunity Scoring

Each keyword is scored using a composite model:

```
Score = (Volume Ã— 0.25) + (Position Ã— 0.20) + (CTR Gap Ã— 0.20) + 
        (Commercial Ã— 0.20) + (Trend Ã— 0.15)
```

- **Volume Score**: Normalized search volume (log scale)
- **Position Score**: Potential based on current ranking (positions 4-15 highest)
- **CTR Gap Score**: Difference vs expected CTR for position
- **Commercial Score**: Based on CPC and competition
- **Trend Score**: Performance change vs previous period

### Decay Detection

Content decay is classified into types:
- **Position Drop**: Position dropped but impressions stable
- **Impressions Drop**: Impressions dropped
- **Clicks Drop**: Clicks dropped significantly
- **CTR Drop**: CTR declined
- **Full Decay**: Multiple metrics declining
- **Demand Shift**: Impressions dropped, position stable
- **Competition Loss**: Position dropped, impressions stable

### Quick Win Criteria

Keywords qualify as quick wins when:
- High impressions (top tier)
- Below-expected CTR for position
- Position in striking distance (3-15)
- High opportunity score

## ğŸ“ˆ Report Sections

### 1. Executive Summary
- Overall organic health assessment
- Key opportunities identified
- Critical actions needed

### 2. Quick Wins
- Top immediate optimization opportunities
- Specific actions with expected impact
- Grouped by optimization type

### 3. Recovery Section
- Declining keywords/pages requiring attention
- Root cause analysis
- Recovery action plan

### 4. Growth Opportunities
- Net-new keyword/topic opportunities
- Content gaps to fill
- Topic clusters to build

### 5. Strategic Recommendations
- Structural changes needed
- Priority investment areas
- Risk mitigation actions

## âš ï¸ Limitations

- GSC data has 3-day delay
- DataForSEO has rate limits based on plan
- YoY comparison requires 1+ year of GSC history
- Large sites may require pagination handling

## ğŸ› ï¸ Troubleshooting

### OAuth Issues
- Ensure redirect URI matches exactly
- Check that Search Console API is enabled
- Verify credentials are correct

### API Errors
- Check DataForSEO credit balance
- Verify OpenRouter API key is valid
- Review rate limit status

### Data Issues
- Ensure property has sufficient data
- Check minimum impressions filter
- Verify date range has data

## ğŸ“ License

This project is proprietary. All rights reserved.

## ğŸ¤ Support

For support, please contact the development team.